<?xml version="1.0" encoding="UTF-8"?>
<!-- Dernière modification
     le       $Date$
     par      $Author$
     révision $Revision$ -->

<sect1 id="slonstart"> <title>Les démons Slon</title>

<indexterm><primary>exécuter le démon slon</primary></indexterm>

<para>Les programmes qui effectuent concrètement la réplication &slony1; sont les démons
<application>slon</application>.</para>

<para>Vous devez lancer une instance <xref linkend="slon"/> sur chaque noeud
  du cluster &slony1; que ce noeud soit considéré comme maître ou esclave.
  Sous &windows;, l'exécution en tant que service est légèrement différente.
  Un service slon est installé, et un fichier de configuration est enregistré
  pour chaque noeud qui devra être servi par la machine. Le service principal
  gère alors lui-même les slons individuels. Puisque qu'une commande 
  <command>MOVE SET</command> ou <command>FAILOVER</command> peut modifier
  le rôle des noeuds, slon doit fonctionner pour tous les noeuds. Il n'est 
  pas essentiel que ces démons soient hébergé sur un hôte particulier, mais
  quelques principes méritent d'être considérés :

<itemizedlist>

<listitem><para> Chaque démon <application>slon</application> doit être capable
    de communiquer rapidement avec la base de données dont il est le <quote>contrôleur</quote>
    Ainsi, si un cluster &slony1; s'étend sur un réseau longue distance (WAN), chaque processus
    slon doit être exécuté sur ou près de la base de données qu'il gère. Si vous 
    enfreignez cette règle, aucun désastre ne s'en suivra mais la latence induite
    pour surveiller les événements sur son propre noeud, impliquera que le démon 
    slon effectuera une réplication <emphasis>un peu</emphasis> moins rapide.
    </para></listitem>

<listitem><para> Les meilleurs résultats sont obtenus en exécutant
    chaque démon <application>slon</application> sur le serveur de 
    base de donnée qu'il contrôle. Si il est exécuté dans un réseau 
    local rapide, les performances ne seront pas dégradées de manières 
    notables.</para></listitem>

<listitem><para> Il est intéressant de lancer plusieurs processus slon
    sur une machine unique, car il est plus simple de surveiller les 
    fichiers de trace et les tables des processus lorsqu'ils se trouvent
    au même endroit. Cela évite également de devoir se connecter à 
    plusieurs hôtes pour lire les fichiers de trace ou pour redémarrer
    les instances <application>slon</application>.</para></listitem>

</itemizedlist>
</para>

<warning><para> <emphasis>Ne lancez pas</emphasis> un démon slon devant 
    gérer un noeud à travers un lien WAN, si possible.
    Tout problème avec ce lien peut tuer les connexions et ainsi laisser 
    des connexions <quote>zombies</quote> sur le noeud qui  subsisteront 
    (de manière générale) pendant environ deux heures. Ceci empêche le démarrage
    d'un autre slon, comme cela est décrit dans la <link linkend="FAQ"> FAQ
</link> au sein de la section sur <link linkend="multipleslonconnections">les connexions
  slon multiples slon</link>. </para> </warning>


<para> Historiquement, les processus <application>slon</application> 
  ont été plutôt fragiles, défaillant dès qu'ils rencontraient une 
  erreur significative. Ce comportement impliquait l'utilisation de 
  <quote>chiens de garde</quote> qui surveille les démons afin 
  de s'assurer que si un <application>slon</application> s'arrête,
  il soit remplacé par un autre. </para>

<para>Il existe deux scripts <quote>chiens de garde</quote> actuellement 
  disponible dans l'arborescence des sources de &slony1; :

<itemizedlist>

<listitem><para> <filename>tools/altperl/slon_watchdog</filename> -
une version <quote>précoce</quote> qui contient basiquement une boucle
autour de l'invocation de <xref linkend="slon"/>, redémarrant à chaque
fois que le démon s'arrête.</para>
</listitem>

<listitem><para> <filename>tools/altperl/slon_watchdog2</filename>
- une version un peu plus intelligente qui sonde régulièrement la
base de donnée, pour vérifier qu'un événement  <command>SYNC</command> 
s'est produit récemment. Nous avons connu des connexions VPN qui se 
terminaient parfois sans avertir l'application, dans ce cas le 
démon <xref linkend="slon"/> s'arrête mais ne meurt pas; Ce mécanisme 
de sondage résout ce problème.</para></listitem>

</itemizedlist></para>

<para>Le script <filename>slon_watchdog2</filename> est 
  <emphasis>en général</emphasis> la solution la plus préférable.
  Il existe un cas ou elle n'est pas préférable : lorsque l'on 
  abonne un très gros ensemble qui nécessitera plusieurs heures
  de <command>COPY SET</command> (le principal événement que provoque
  la requête <command>SUBSCRIBE SET</command>). Le problème qui surgit
  dans ce cas est que le chien de garde constate qu'aucun événement <command>SYNC</command> 
  n'a été produit depuis 2 heures, et déduit que quelque
  est cassé, ce qui implique un redémarrage du démon slon, ce qui redémarre
  également le <command>COPY SET</command>.  
  Récemment le script a été modifié pour détecter les <command>COPY SET</command> 
  en cours d'exécution.</para>

<para>Dans &slony1; version 1.2, la structure du démon
<application>slon</application> a été révisée de manière importante
pour le rendre moins fragile. Le processus principal ne s'arrête que si vous envoyez 
expressément un signal lui demandant de s'arrêter. </para>

<para> Une nouvelle approche est disponible dans le script <xref
linkend="launchclusters"/> qui utilise les fichiers de configuration
<application>slon</application> et peut être invoqué comme un service dans
le processus de démarrage du système.</para>

</sect1>
