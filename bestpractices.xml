<?xml version="1.0" encoding="UTF-8"?>
<!-- Dernière modification
     le       $Date$
     par      $Author$
     révision $Revision$ -->

<sect1 id="bestpractices">
<title> &slony1; <quote>Bonnes Pratiques</quote> </title>
<indexterm><primary>bonnes pratiques pour utiliser &slony1;</primary></indexterm>

<para> Il est courant pour les administrateurs de vouloir exploiter des systèmes 
  en utilisant un ensemble de <quote>bonnes pratiques</quote> disponibles et documentées.
  Documenter ce genre de choses est essentiel pour l'ISO 9000, l'ISO 9001, 
  et d'autres type de certifications d'organisation. </para>

<para> Il est intéressant d'introduire toute discussion sur des <quote>bonnes
pratiques</quote> en mentionnant que chaque organisation utilisant &slony1; est unique,
et qu'il est nécessaire qu'une politique locale reflète les caractéristiques administratives locales.
C'est pour cette raison que &slony1; n'impose <emphasis>as</emphasis> ses propres règles pour des 
choses telles que <link linkend="failover">les bascules d'urgence</link>; elles devront être déterminées
en fonction de l'architecture globale de votre réseau, de votre ensemble de serveurs de base de données, 
et de votre manière d'utiliser ces serveurs.</para>

<para> Il ya toutefois, un certain nombre de choses que les pioniers de &slony1; ont
  découvertes qui peuvent au moins aider à concevoir le genre de règles d'administration
  que vous pourriez mettre en place. </para>

<itemizedlist>

<listitem>
<para> &slony1; est système multi-clients et multi-serveurs complexe,
ce qui implique qu'il existe un ensemble presque infini d'endroits 
où des problèmes peuvent surgir.</para> 

<para> c'est donc naturellement que la maintenance d'un environement propre, cohérent
 est réellement décisif, car tout type de <quote>cafouillage</quote> dans l'environnement
 peut provoquer des problèmes ou masquer le problème réel. </para>

<para> De nombreux utilisateurs ont rapportés des problèmes provenants d'incompatibilités
  entre les versions de &slony1;, les librairies locales, et les librairies de &postgres;.
  Chaque détail compte : vous devez identifier clairement sur quels hôtes sont hébergées 
  quelles versions de quels logiciels. </para>

<para> Normalement il s'agit juste d'être discipliné lors du déploiement de vos logiciels, et 
  ce défi est une conséquence naturelle lorsqu'on met en place un système distribué constitué
  par un grand nombre de composants qui doivent correspondre.</para>
</listitem>

<listitem><para> Si un script slonik ne fonctionne pas comme prévu à la première 
    tentative, il serait téméraire de tenter de l'exécuter à nouveau tant que le 
    problème n'a pas été trouvé et résolu.  </para>

<para> Il y a très peu de commandes slonik tel que <xref
linkend="stmtstorepath"/> qui se comporte de manière déterministe;
  si vous exécuter <xref linkend="stmtstorepath"/> plusieurs fois,
  cela mettra plusieurs fois la même valeur dans la table
  <envar>sl_path</envar>.  </para>

<para> Au contraire <xref linkend="stmtsubscribeset"/> se comporte de 
  deux manières <emphasis>très</emphasis> différentes selon si 
  l'abonnement a déjà été activé ou pas; si l'initialisation de 
  l'abonnement n'a pas fonctionné à la toute première tentative, 
  soumettre à nouveau cette requête n'arrangera <emphasis>pas</emphasis>
  la situation. </para>
</listitem>

<listitem>
<para> Principe: Utilisez un zone de temps ("timezone") stable et non-ambigüe 
  tel que UTC ou GMT.</para>

<para> Les utilisateurs ont rencontrés des problèmes pour faire fonctionner
  &lslon; correctement lorsque leur système utilisait une zone de temps que 
  &postgres; ne pouvait pas reconnaitre tel que CUT0 ou WST. Il est nécessaire
  que vous utilisiez une zone de temps que &postgres; reconnaît correctement.
  De plus, il est préférable d'utiliser une zone qui n'est pas soumise au 
  basculement entre heure d'été et heure d'hivers.</para>

<para> Le choix <quote>géographiquement neutre</quote> semble être
 <command><envar>TZ</envar>=UTC</command> ou
<command><envar>TZ</envar>=GMT</command>, par ailleurs assurez-vous que 
vos serveurs sont <quote>synchronisés</quote> grace à l'utilisation 
de NTP sur l'ensemble de votre environnement. </para>

<para> Voir aussi <xref linkend="times"/>.</para>
</listitem>

<listitem>
<para> Principe: Les transactions longues c'est mal </para>

<para> La FAQ a un chapitre sur la<link linkend="pglistenerfull">croissance de
 &pglistener; </link> qui explique tout cela en détails; pour simplifier :
les transactions longues ont de nombreux effets secondaires. Elles sont problématiques
en particulier sur un noeud <quote>origine</quote>, s'accaparant les verrous, rendant inefficace 
les vacuums , et ainsi de suite.</para>

<para> Dans la version 1.2, certains comportement <quote>désagréables</quote> devraient
  être diminués car :</para>

<itemizedlist>

<listitem><para> Les événements dans &pglistener; sont seulement générés lorsque
    les mise à jours de réplication sont relativement rare, ce qui devrait 
    impliquer que les systèmes chargés ne vont pas générer beaucoup de tuples morts
    dans cette table.
</para></listitem>

<listitem><para> Le système va périodiquement faire une rotation (en utilisant 
  <command>TRUNCATE</command> pour nettoyer l'anccienne table) entre les deux tables de logs,
   <xref linkend="table.sl-log-1"/> et <xref
linkend="table.sl-log-2"/>, évitant une croissance illimitée de l'espace <quote>mort</quote> à cet endroit.  </para></listitem>
</itemizedlist>

</listitem>

<listitem>
<para>Les règles de  <link linkend="Failover"> Bascule en urgence </link> 
  devraient être planifiées à l'avance.  </para>

<para> Cela peut simplement se résumer à réfléchir à une liste
  de priorité indiquant ce qui devrait basculer vers quoi, plutot 
  que d'essayer d'automatiser la bascule. Quoiqu'il en soit savoir
  au prélable ce qu'il faut faire réduit le nombre d'erreurs commises.
  </para>

<para> Chez Afilias, une grande variété de guide interne, tel que <citation>Le guide 
    de l'administrateur réveillé à 3 heures du matin..</citation>, ont été
    rédigé pour fournir les procédures à suivre en cas d'événements <quote>malheureux</quote>.
    Ce genre de matériel est hautement spécifique à l'environnement  et à l'ensemble d'applications
    présentes, donc vous devriez rédiger vos propres documents. Ceci est un des composants vitaux de 
    tout procédure de reprise après crash.
</para>
</listitem>

<listitem><para> <xref linkend="stmtmoveset"/> should be used to allow
preventative maintenance to prevent problems from becoming serious
enough to require <link linkend="failover"> failover </link>. </para>
</listitem>

<listitem> <para> <command>VACUUM</command> policy needs to be
carefully defined.</para>

<para> As mentioned above, <quote>long running transactions are
Evil.</quote> <command>VACUUM</command>s are no exception in this.  A
<command>VACUUM</command> on a huge table will open a long-running
transaction with all the known ill effects.</para>
</listitem>

<listitem><para> If you are using the autovacuum process in recent
versions of &postgres;, you may wish to leave &slony1; tables out, as
&slony1; is a bit more intelligent about vacuuming when it is expected
to be conspicuously useful (<emphasis>e.g.</emphasis> - immediately
after purging old data) to do so than autovacuum can be. </para>

<para> See <xref linkend="maintenance-autovac"/> for more
details. </para> </listitem>


<listitem> <para> Running all of the &lslon; daemons on a central
server for each network has proven preferable. </para>

<para> Each &lslon; should run on a host on the same local network as
the node that it is servicing, as it does a <emphasis>lot</emphasis>
of communications with its database, and that connection needs to be
as reliable as possible.  </para>

<para> In theory, the <quote>best</quote> speed might be expected to
come from running the &lslon; on the database server that it is
servicing. </para>

<para> In practice, strewing &lslon; processes and configuration
across a dozen servers turns out to be inconvenient to manage.</para>
</listitem>

<listitem><para> &lslon; processes should run in the same
<quote>network context</quote> as the node that each is responsible
for managing so that the connection to that node is a
<quote>local</quote> one.  Do <emphasis>not</emphasis> run such links
across a WAN. </para>

<para> A WAN outage can leave database connections
<quote>zombied</quote>, and typical TCP/IP behaviour <link
linkend="multipleslonconnections"> will allow those connections to
persist, preventing a slon restart for around two hours. </link>
</para>

<para> It is not difficult to remedy this; you need only <command>kill
SIGINT</command> the offending backend connection.  But by running the
&lslon; locally, you will generally not be vulnerable to this
condition. </para>
</listitem>

<listitem><para> Before getting too excited about having fallen into
some big problem, consider killing and restarting all the &lslon;
processes.  Historically, this has frequently been able to
resolve <quote>stickiness.</quote> </para>

<para> With a very few exceptions, it is generally not a big deal to
kill off and restart the &lslon; processes.  Each &lslon; connects to
one database for which it is the manager, and then connects to other
databases as needed to draw in events.  If you kill off a &lslon;, all
you do is to interrupt those connections.  If
a <command>SYNC</command> or other event is sitting there
half-processed, there's no problem: the transaction will roll back,
and when the &lslon; restarts, it will restart that event from
scratch.</para>

<para> The exception, where it is undesirable to restart a &lslon;, is
where a <command>COPY_SET</command> is running on a large replication
set, such that stopping the &lslon; may discard several hours worth of
load work. </para>

<para> In early versions of &slony1;, it was frequently the case that
connections could get a bit <quote>deranged</quote> which restarting
&lslon;s would clean up.  This has become much more rare, but it has
occasionally proven useful to restart the &lslon;.  If there has been
any <quote>network derangement</quote>, this can clear up the issue of
defunct database connections.  </para> </listitem>

<listitem>
<para>The <link linkend="ddlchanges"> Database Schema Changes </link>
section outlines some practices that have been found useful for
handling changes to database schemas. </para></listitem>

<listitem>
<para> Handling of Primary Keys </para> 

<para> Discussed in the section on <link linkend="definingsets">
Replication Sets, </link> it is <emphasis>ideal</emphasis> if each
replicated table has a true primary key constraint; it is
<emphasis>acceptable</emphasis> to use a <quote>candidate primary
key.</quote></para>

<para> It is <emphasis>not recommended</emphasis> that a
&slony1;-defined key (created via <xref linkend="stmttableaddkey"/>) be
used to introduce a candidate primary key, as this introduces the
possibility that updates to this table can fail due to the introduced
unique index, which means that &slony1; has introduced a new failure
mode for your application.</para>


<warning><para> In version 2 of &slony1;, <xref
linkend="stmttableaddkey"/> is no longer supported.  You
<emphasis>must</emphasis> have either a true primary key or a
candidate primary key.  </para></warning>
</listitem>

<listitem>
<para> <link linkend="definesets"> Grouping tables into sets
</link> suggests strategies for determining how to group tables and
sequences into replication sets. </para>
</listitem>

<listitem>
<para> It should be obvious that actions that can delete a
lot of data should be taken with great care; the section on <link
linkend="dropthings"> Dropping things from &slony1; Replication</link>
discusses the different sorts of <quote>deletion</quote> that &slony1;
supports.  </para>
</listitem>

<listitem>
<para> <link linkend="Locking"> Locking issues </link></para>

<para> Certain &slony1; operations, notably <link
linkend="stmtsetaddtable"> <command>set add table</command> </link>,
<link linkend="stmtmoveset"> <command> move set</command> </link>,
<link linkend="stmtlockset"> <command> lock set </command> </link>,
and <link linkend="stmtddlscript"> <command>execute script</command>
</link> require acquiring <emphasis>exclusive locks</emphasis> on the
tables being replicated. </para>

<para> Depending on the kind of activity on the databases, this may or
may not have the effect of requiring a (hopefully brief) database
outage. </para>
</listitem>

<listitem><para> What to do about DDL. </para>

<para> &slony1; operates via detecting updates to table data via
triggers that are attached to those tables.  That means that updates
that take place via methods that do not fire triggers will not notice
those updates.  <command>ALTER TABLE</command>, <command>CREATE OR
REPLACE FUNCTION</command>, <command>CREATE TABLE</command>, all
represent SQL requests that &slony1; has no way to notice. </para>

<para> A philosophy underlying &slony1;'s handling of this is that
competent system designers do not write self-modifying code, and
database schemas that get modified by the application are an instance
of this.  It does not try hard to make it convenient to modify
database schemas. </para>

<para> There will be cases where that is necessary, so the <link
linkend="stmtddlscript"> <command>execute script</command> is provided
which will apply DDL changes at the same location in the transaction
stream on all servers.  </link> </para>

<para> Unfortunately, this introduces a great deal of locking of
database objects.  Altering tables requires taking out an exclusive
lock on them; doing so via <command>execute script</command> requires
that &slony1; take out an exclusive lock on <emphasis>all</emphasis>
replicated tables.  This can prove quite inconvenient when
applications are running; you run into deadlocks and such. </para>

<para> One particularly dogmatic position that some hold is that
<emphasis>all</emphasis> schema changes should
<emphasis>always</emphasis> be propagated using <command>execute
script</command>.  This guarantees that nodes will be consistent, but
the costs of locking and deadlocking may be too high for some
users.</para>

<para> At Afilias, our approach has been less dogmatic; there
<emphasis>are</emphasis> sorts of changes that
<emphasis>must</emphasis> be applied using <command>execute
script</command>, but we apply others independently.</para>

<itemizedlist>
<listitem><para> Changes that must be applied using <command>execute script</command> </para>
<itemizedlist>
<listitem><para> All instances of <command>ALTER TABLE</command></para></listitem>
</itemizedlist>

</listitem>
<listitem><para> Changes that are not normally applied using <command>execute script</command> </para>
<itemizedlist>
<listitem><para> <command>CREATE INDEX</command> </para></listitem>
<listitem><para> <command>CREATE TABLE</command> </para>
<para> Tables that are not being replicated do not require &slony1; <quote>permission</quote>. </para></listitem>

<listitem><para> <command>CREATE OR REPLACE FUNCTION </command> </para>

<para> Typically, new versions of functions may be done without
&slony1; being <quote>aware</quote> of them.  The obvious exception is
when a new function is being deployed to accomodate a table
alteration; in that case, the new version must be added in in a manner
synchronized with the <command>execute script</command> for the table
alteration. </para>

<para> Similarly, <command>CREATE TYPE</command>, <command> CREATE
AGGREGATE </command>,  and such will
commonly not need to be forcibly applied in <quote>perfectly
synchronized</quote> manner across nodes. </para></listitem>

<listitem><para> Security management, such as <command> CREATE USER
</command>, <command> CREATE ROLE </command>, <command>GRANT
</command>, and such are largely irrelevant to &slony1; as it runs as
a <quote>superuser</quote>. </para>

<para> Indeed, we have frequently found it useful to have different
security arrangements on different nodes.  Access to the
<quote>master</quote> node should be restricted to applications that
truly need access to it; <quote>reporting</quote> users commonly are
restricted much more there than on subscriber nodes.</para>

</listitem>
</itemizedlist>
</listitem>
</itemizedlist>

</listitem>

<listitem id="slonyuser"> <para> &slony1;-specific user names. </para>

<para> It has proven useful to define a <command>slony</command> user
for use by &slony1;, as distinct from a generic
<command>postgres</command> or <command>pgsql</command> user.  </para>

<para> If all sorts of automatic <quote>maintenance</quote>
activities, such as <command>vacuum</command>ing and performing
backups, are performed under the <quote>ownership</quote> of a single
&postgres; user, it turns out to be pretty easy to run into deadlock
problems. </para>

<para> For instance, a series of <command>vacuums</command> that
unexpectedly run against a database that has a large
<command>SUBSCRIBE_SET</command> event under way may run into a
deadlock which would roll back several hours worth of data copying
work.</para>

<para> If, instead, different maintenance roles are performed by
different users, you may, during vital operations such as
<command>SUBSCRIBE_SET</command>, lock out other users at the
<filename>pg_hba.conf</filename> level, only allowing the
<command>slony</command> user in, which substantially reduces the risk
of problems while the subscription is in progress.
</para>
</listitem>

<listitem>
<para> Path configuration </para> 

<para> The section on <link linkend="plainpaths"> Path Communications
</link> discusses the issues surrounding what network connections need
to be in place in order for &slony1; to function.</para>
</listitem>

<listitem><para> Lowering Authority </para>

<para> Traditionally, it has been stated that <quote>&slony1; needs to
use superuser connections.</quote> It turns out that this is not
entirely true, and and if there are particular concerns about
excessive use of superuser accounts, it is possible to reduce this
considerably. </para>

<para> It is true to say that each &lslon; <emphasis>must</emphasis>
have a superuser connection in order to manage the node that it is
assigned to.  It needs to be able to alter the system catalogue in
order to set up subscriptions and to process alterations
(<emphasis>e.g</emphasis> - to run <xref linkend="stmtddlscript"/> and
other events that may alter the role of replicated tables on the local
node).  </para>

<para> However, the connections that &lslon; processes open to other
nodes to access events and process subcriptions do not need to have
nearly so much permission.  Indeed, one could set up a <quote>weak
user</quote> assigned to all <xref linkend="stmtstorepath"/> requests.
The minimal permissions that this user, let's call it
<command>weakuser</command>, requires are as follows:</para>

<itemizedlist>
<listitem><para> It must have read access to the &slony1;-specific namespace </para> </listitem>
<listitem><para> It must have read access to all tables and sequences in that namespace</para> </listitem>
<listitem><para> It must have write access to the &slony1; table <envar>sl_nodelock</envar> and sequence <envar>sl_nodelock_nl_conncnt_seq</envar> </para> </listitem>
<listitem><para> At subscribe time, it must have read access to all of the replicated tables. </para> 
<para> Outside of subscription time, there is no need for access to access to the replicated tables. </para> </listitem>
<listitem><para> There is some need for read access to tables in pg_catalog; it has not been verified how little access would be suitable. </para> </listitem>
</itemizedlist>

<para> In version 1.3, the tests in the <xref linkend="testbed"/>
support using a <envar>WEAKUSER</envar> so that testing can regularly
confirm the minimal set of permissions needed to support
replication.</para>

</listitem>

<listitem><para> The section on <link linkend="listenpaths"> listen
paths </link> discusses the issues surrounding the table <xref
linkend="table.sl-listen"/>.</para>

<para> As of &slony1; 1.1, its contents are computed automatically
based on the communications information available to &slony1; which
should alleviate the problems found in earlier versions where this had
to be configured by hand.  Many seemingly inexplicable communications
failures, where nodes failed to talk to one another even though they
technically could, were a result of incorrect listen path
configuration. </para>
</listitem>

<listitem><para> Use <filename>test_slony_state.pl</filename> to look
for configuration problems.</para>

<para>This is a Perl script which connects to a &slony1; node and then
rummages through &slony1; configuration looking for quite a variety of
conditions that tend to indicate problems, including:
<itemizedlist>
<listitem><para>Bloating of some config tables</para></listitem>
<listitem><para>Analysis of listen paths</para></listitem>
<listitem><para>Analysis of event propagation and confirmation</para></listitem>
</itemizedlist></para>

<para> If replication mysteriously <quote>isn't working</quote>, this
tool can run through many of the possible problems for you. </para>

</listitem>

<listitem>
<para> Configuring &lslon; </para> 

<para> As of version 1.1, &lslon; configuration may be
drawn either from the command line or from configuration files.
<quote>Best</quote> practices have yet to emerge from the two
options:</para>
</listitem>
</itemizedlist>

<itemizedlist>

<listitem>
<para> Configuration via command line options</para> 

<para> This approach has the merit that all the options that are
active are visible in the process environment.  (And if there are a
lot of them, they may be a nuisance to read.)</para>

<para> Unfortunately, if you invoke &lslon; from the
command line, you could <emphasis>forget</emphasis> to include
&logshiplink; configuration and thereby destroy the sequence of logs
for a log shipping node. </para>
</listitem>

<listitem> <para> Unlike when command line options are used, the
active options are <emphasis>not</emphasis> visible.  They can only be
inferred from the name and/or contents of the &lslon;
configuration file, and will not reflect subsequent changes to the
configuration file.  </para>

<para> By putting the options in a file, you won't forget including
any of them, so this is safer for &logshiplink;. </para>
</listitem>

</itemizedlist>
<itemizedlist>

<listitem><para> Things to do when subscribing nodes </para>

<para> When a new node is running the <command>COPY_SET</command>
event for a large replication set (<emphasis>e.g.</emphasis> - one
which takes several hours to subscribe) it has been found to be
desirable to lock all users other than the <command>slony</command>
user out of the new subscriber because:
</para>
</listitem>
</itemizedlist>
<itemizedlist>

<listitem><para> Applications will run into partially-copied,
half-baked data that is not totally consistent. </para> </listitem>

<listitem><para> It is possible for applications (and maintenance
scripts) to submit combinations of queries that will get the system
into a deadlock situation, thereby terminating the
<command>COPY_SET</command> event, and requiring the subscription to
start over again.  </para> </listitem>

</itemizedlist>

<para> It <emphasis>may</emphasis> be worth considering turning the
&postgres; <function>fsync</function> functionality off during the
copying of data, as this will improve performance, and if the database
<quote>falls over</quote> during the <command>COPY_SET</command>
event, you will be restarting the copy of the whole replication
set.</para>

<itemizedlist>
<listitem><para> Managing use of slonik </para> 

<para> The notes on <link linkend="usingslonik"> Using Slonik </link>
describe some of the lessons learned from managing large numbers of
<xref linkend="slonik"/> scripts.</para>

<para> Notable principles that have fallen out of generating many
slonik scripts are that:

<itemizedlist>

<listitem><para>Using <quote>preamble</quote> files is
<emphasis>highly recommended</emphasis> as it means that you use
heavily-verified preambles over and over.</para></listitem>

<listitem><para>Any opportunity that you have to automatically
generate configuration whether by drawing it from a database or by
using a script that generates repetitively similar elements will help
prevent human error.</para></listitem>

</itemizedlist>
</para>
</listitem>

<listitem><para> Handling Very Large Replication Sets </para>

<para> Some users have set up replication on replication sets that are
tens to hundreds of gigabytes in size, which puts some added
<quote>strain</quote> on the system, in particular where it may take
several days for the <command>COPY_SET</command> event to complete.
Here are some principles that have been observed for dealing with
these sorts of situations.</para></listitem>

</itemizedlist>

<itemizedlist>

<listitem><para> Drop all indices other than the primary key index
while the <command>COPY_SET</command> event is run. </para>

<para> When data is copied into a table that has indices on it,
&postgres; builds the indices incrementally, on the fly.  This is much
slower than simply copying the data into the table, and then
recreating each index <quote>ex nihilo</quote>, as the latter can take
substantial advantage of sort memory. </para>

<para> In &slony1; version 1.1.5 and later versions, indices are
dropped and recreated automatically, which effectively invalidates
this practice.</para>
</listitem>

<listitem><para> If there are large numbers of updates taking place as
the large set is being copied, this can lead to the subscriber being
behind by some enormous number of <command>SYNC</command> events.</para>

<para> If a <command> SYNC </command> is generated about once per
second, that leads to the subscriber <quote>falling behind</quote> by
around 90,000 <command>SYNC</command>s per day, possibly for several
days.  </para>

<para> There will correspondingly be an <emphasis>enormous</emphasis>
growth of <xref linkend="table.sl-log-1"/> and <xref
linkend="table.sl-seqlog"/>.  Unfortunately, once the
<command>COPY_SET</command> completes, users have found that the
queries against these tables wind up reverting to <command>Seq
Scans</command> so that even though a particular
<command>SYNC</command> processing event is only processing a small
number of those 90,000 <command>SYNC</command> events, it still reads
through the entire table.  In such a case, you may never see
replication catch up.
</para> 

<para> Several things can be done that will help, involving
careful selection of &lslon; parameters:</para>
</listitem>
</itemizedlist>

<itemizedlist>

<listitem><para> Ensure that there exists, on the
<quote>master</quote> node, an index on <function> sl_log_1(log_xid)
</function>.  If it doesn't exist, as the &slony1; instance was set up
before version 1.1.1, see <filename> slony1_base.sql </filename> for
the exact form that the index setup should take. </para> 

<para> In 1.2 and later versions, there is a process that runs
automatically to add partial indexes by origin node number, which
should be the optimal form for such an index to take.  </para>
</listitem>

<listitem><para> On the subscriber's &lslon;, increase
the number of <command>SYNC</command> events processed together, with
the <xref linkend= "slon-config-sync-group-maxsize"/> parameter to some
value that allows it to process a significant portion of the
outstanding <command>SYNC</command> events. </para> </listitem>

<listitem><para> On the subscriber's &lslon;, set the
<xref linkend="slon-config-desired-sync-time"/> to 0, as the adaptive
<command>SYNC</command> grouping system will start with small
groupings that will, under these circumstances, perform
poorly. </para> </listitem>

<listitem><para> Increase the <xrefls
linkend="slon-config-sync-interval"/> on the origin's <xref
linkend="slon"/> so that <command>SYNC</command> events are generated
less frequently.  If a <command>SYNC</command> is only generated once
per minute instead of once per second, that will cut down the number
of events by a factor of 60. </para> </listitem>
</itemizedlist>

<itemizedlist>
<listitem><para> It is likely to be worthwhile to use <xref
linkend="slon-config-vac-frequency"/> to deactivate <xref
linkend="slon"/>-initiated vacuuming in favor of running your own
vacuum scripts, as there will be a buildup of unpurgeable data while
the data is copied and the subscriber starts to catch up. </para>
</listitem>
</itemizedlist>

</sect1>
